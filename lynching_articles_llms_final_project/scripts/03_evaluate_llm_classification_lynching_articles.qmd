---
title: "final_final_project"
---

```{r}

###
# Step 01 Load libraries +
# Edit .Renviron file to add API Keys
# Restart R after editing .Renviron files
###
source("r_scripts/03_01_r_environment_setup.R")

###
# Step 02 Define model list
###
source("r_scripts/03_02_r_provider_model_list.R")

###
# Step 03 Define system prompt to send with each article
###

source("r_scripts/03_03_r_system_prompt.R")

###
# Load function to classify articles
###
source("r_scripts/03_04_r_classify_articles.R")

###
# Load function to combine and evaluate responses
###

source("r_scripts/03_05_r_evaluate_responses.R")

###
# Load function to correct malformed json with llm
###

source("r_scripts/03_06_r_check_and_correct_json.R")


###
# Load test data
###
test_data <- read_rds("../data/input_data/03_test_data.rds")

```

```{r eval=FALSE}



###
# Classify articles
###

###
# Run function for all articles in parallel
###

# Set up parallel processing
workers <- parallel::detectCores() - 1
future::plan(future::multisession, workers = workers)

# Run classification in parallel
future_map(
  provider_model_type_list,
  classify_articles,
  system_prompt = system_prompt_value,
  test_set_articles_df = test_data,
  sample_size = nrow(test_data),
  overwrite = FALSE,
  .progress = TRUE
)

###
# Function to classify articles
###

##
# For testing, run function for a single model
##
classify_articles(
 model_provider_type = "gemini_gemini-exp-1114",
 system_prompt = system_prompt_value,
 test_set_articles_df = test_data,
 sample_size = nrow(test_data),
 overwrite = FALSE
)
```

```{r}
###
# Parse model responses
###

responses <- combine_responses_validate_json("../data/output_data/llm_responses") %>%
  filter(!str_detect(model_type,"1114"))

###
# Check for completeness
###

response_check <- get_model_completeness_status()[[2]]
  
###
# Check and correct malformed json
###

output_dir <- correct_malformed_json_with_llm(responses, n_workers = 10)


# Example usage:
# Process the data and save to files:
#output_dir <- correct_malformed_json_with_llm(responses, n_workers = 10)
#
# Later, when needed, combine all results:
combined_df <- combine_json_results(output_dir)

x <- combined_df %>%
  group_by(article_id, model_provider, model_type, recheck_valid_json_in_raw_response) %>%
  count() %>%
  ungroup() %>%
  mutate(recheck_valid_json_in_raw_response = replace_na(as.character(recheck_valid_json_in_raw_response), "NA")) %>%
  pivot_wider(names_from=recheck_valid_json_in_raw_response, values_from=n) %>%
  mutate(`NA` = replace_na(`NA`, 0),
         `FALSE` = replace_na(`FALSE`, 0),
         `TRUE` = replace_na(`TRUE`, 0)) %>%
  mutate(total = sum(`NA`, `FALSE`, `TRUE`)) %>%
  distinct(article_id, model_provider, model_type)
  filter(`NA` == 1, `FALSE` == 1) 
  arrange(desc(n))
  filter(recheck_valid_json_in_raw_response == FALSE) %>%
  select(raw_response, repaired_json, recheck_valid_json_in_raw_response) %>%
  slice(1:3)





```

```{r}



```

```{r}

###
# Parse responses
###

source("r_scripts/03_05_r_evaluate_responses.R")

responses <- combine_responses_validate_json()
#responses <- responses %>%
 # filter(valid_json_in_raw_response == FALSE) %>%
#slice(1:3)
library(furrr)
library(future)
library(R.utils)
library(progress)

correct_malformed_json_with_llm <- function(df, n_workers = 3) {
  # Set up parallel processing
  plan(multisession, workers = n_workers)
  
  # Create chat client factory function to ensure each worker has its own client
  create_chat_client <- function() {
    chat_openai(
      model = "gpt-4-turbo",
      system_prompt = "I will pass you a malformed json object. Your task is to fix any errors that will prevent this from returning TRUE when passed directly through the jsonlite::validate() function in R. Do not change the content of the json object, only the structure.Format your response as a JSON object with these exact fields:{
          \"article_id\": \"string, unchanged from input\",
          \"spellchecked_text\": \"string, corrected spelling of article\",
          \"category_id\": \"string, single digit 1-6\",
          \"category_description\": \"string, exact category description from above\",
          \"explanation\": \"string, brief reason for classification\"}
      
      If a value is missing for a specific key, or if a key is not present at all, include the key with an empty string as the value in your response. Important formatting rules:
      - Use double quotes for all strings
      - No line breaks in text fields
      - No trailing commas
      - No comments or additional text
      - No markdown formatting
      - Escape all quotes within text using single quotes
      - Remove any \\r or \\n characters from text
      - End the JSON object with a single closing curly brace }",
      echo = FALSE
    )
  }
  
  # Process function for each row
  process_row <- function(raw_response, valid_json_in_raw_response) {
    if (valid_json_in_raw_response) {
      return(raw_response)
    }
    
    # Create a new chat client for this worker
    chat <- create_chat_client()
    
    # Add timeout and retry logic
    tryCatch({
      R.utils::withTimeout({
        attempt <- 1
        max_attempts <- 3
        result <- NULL
        
        while (attempt <= max_attempts && is.null(result)) {
          result <- tryCatch({
            chat$chat(raw_response)
          }, error = function(e) {
            if (attempt == max_attempts) {
              return(paste0("Error after ", max_attempts, " attempts: ", e$message))
            }
            Sys.sleep(2^attempt)  # Exponential backoff
            return(NULL)
          })
          attempt <- attempt + 1
        }
        result
      }, timeout = 30)
    }, error = function(e) {
      paste0("Error: ", e$message)
    })
  }
  
  # Add progress bar
  pb <- progress::progress_bar$new(
    format = "[:bar] :current/:total (:percent) :eta",
    total = nrow(df)
  )
  
  # Process in parallel with progress updates
  repaired_json <- df %>%
    mutate(
      repaired_json = future_map2(
        raw_response,
        valid_json_in_raw_response,
        ~{
          result <- process_row(.x, .y)
          pb$tick()
          result
        },
        .options = furrr_options(seed = TRUE)
      )
    ) %>%
    mutate(
      recheck_valid_json_in_raw_response = map_lgl(repaired_json, ~tryCatch(
        jsonlite::validate(.x),
        error = function(e) FALSE
      ))
    )
  
  # Clean up parallel processing
  plan(sequential)
  
  # Enhanced summary statistics
  n_total <- nrow(repaired_json)
  n_already_valid <- sum(df$valid_json_in_raw_response)
  n_needed_repair <- n_total - n_already_valid
  n_fixed <- sum(repaired_json$recheck_valid_json_in_raw_response & !repaired_json$valid_json_in_raw_response)
  n_failed <- sum(!repaired_json$recheck_valid_json_in_raw_response & !repaired_json$valid_json_in_raw_response)
  
  # Create summary attributes
  attr(repaired_json, "summary") <- list(
    total_processed = n_total,
    already_valid = n_already_valid,
    needed_repair = n_needed_repair,
    successfully_fixed = n_fixed,
    failed_to_fix = n_failed
  )
  
  # Print detailed summary
  message(sprintf("\nProcessing Summary:
Total JSON objects processed: %d
- Already valid (no repair needed): %d
- Needed repair: %d
  └─ Successfully fixed: %d
  └─ Failed to fix: %d", 
    n_total, n_already_valid, n_needed_repair, n_fixed, n_failed))
  
  return(repaired_json)
}

# Example usage:
fixed <- correct_malformed_json_with_llm(responses, n_workers = 5)
# 
# To access summary later:
# summary_stats <- attr(fixed, "summary")
# Example usage:

```

```{r}

df <- responses %>%
  slice(1:2)
correct_malformed_json_with_llm <- function(df) {
  
  chat <- chat_openai(
        model = "gpt-4-turbo",
        system_prompt = "I will pass you a malformed json object. Your task is to fix any errors that will prevent this from returning TRUE when passed directly through the jsonlite::validate() function in R. Do not change the content of the json object, only the structure.Format your response as a JSON object with these exact fields:{
            \"article_id\": \"string, unchanged from input\",
            \"spellchecked_text\": \"string, corrected spelling of article\",
            \"category_id\": \"string, single digit 1-6\",
            \"category_description\": \"string, exact category description from above\",
            \"explanation\": \"string, brief reason for classification\"}
        
        If a value is missing for a specific key, or if a key is not present at all, include the key with an empty string as the value in your response. Important formatting rules:
- Use double quotes for all strings
- No line breaks in text fields
- No trailing commas
- No comments or additional text
- No markdown formatting
- Escape all quotes within text using single quotes
- Remove any \\r or \\n characters from text
- End the JSON object with a single closing curly brace }",

echo = FALSE)
  
  repaired_json <- df %>%
      #filter(valid_json_in_raw_response == FALSE) %>%
      #slice(1) %>%
      mutate(repaired_json = case_when(
        valid_json_in_raw_response == TRUE ~ raw_response,
        
        TRUE ~ tryCatch(
            chat$chat(raw_response),
            error = function(e) paste0("Error: ", e$message)
            ))
        ) %>%
    mutate(recheck_valid_json_in_raw_response = map_lgl(repaired_json, ~tryCatch(
    jsonlite::validate(.x),
    error = function(e) FALSE
  ))) 
    
  return(repaired_json)  
}

fixed <- correct_malformed_json_with_llm(responses)



json_class_responses <- responses %>%
  mutate(valid_json_in_raw_response = map_lgl(raw_response, ~tryCatch(
    jsonlite::validate(.x),
    error = function(e) FALSE
  ))) 
```

```{r}
###
# Combine individual model responses into a single data frame
###
source("r_scripts/03_05_r_evaluate_responses.R")
#responses <- combine_responses()
responses <- combine_responses_2() 

json_class_responses <- responses %>%
  mutate(valid_json_in_raw_response = map_lgl(raw_response, ~tryCatch(
    jsonlite::validate(.x),
    error = function(e) FALSE
  ))) 

good_at_json_parsing <- json_class_responses %>%
  mutate(model_provider_type = paste0(model_provider, "_", model_type)) %>%
  group_by(model_provider_type, valid_json_in_raw_response) %>%
  count() %>%
  pivot_wider(names_from=valid_json_in_raw_response, values_from=n)  %>%
  replace_na(list(`TRUE` = 0, `FALSE` = 0))

chat <- chat_openai(model = "gpt-4-turbo",
        system_prompt = "I will pass you a malformed json object. 

        Your task is to fix any errors that will prevent this from returning TRUE when passed directly through the jsonlite::validate() function in R. Do not change the content of the json object, only the structure.  
        Format your response as a JSON object with these exact fields:
        {
            \"article_id\": \"string, unchanged from input\",
            \"spellchecked_text\": \"string, corrected spelling of article\",
            \"category_id\": \"string, single digit 1-6\",
            \"category_description\": \"string, exact category description from above\",
            \"explanation\": \"string, brief reason for classification\"
        }
        
        If a value is missing for a specific key, or if a key is not present at all, include the key with an empty string as the value in your response. 
        
Important formatting rules:
- Use double quotes for all strings
- No line breaks in text fields
- No trailing commas
- No comments or additional text
- No markdown formatting
- Escape all quotes within text using single quotes
- Remove any \\r or \\n characters from text
- End the JSON object with a single closing curly brace }",

echo = FALSE)

fix_json <- json_class_responses %>%
  filter(valid_json_in_raw_response == FALSE) %>%
  slice(1:5) %>%
  mutate(repaired_json = case_when(
    valid_json_in_raw_response == TRUE ~ raw_response,
    TRUE ~ chat$chat(raw_response))
  ) %>%
  mutate(recheck_valid_json_in_raw_response = map_lgl(repaired_json, ~tryCatch(
    jsonlite::validate(.x),
    error = function(e) FALSE
  ))) 
           
           
    
  

response <- chat$chat(text)

saveRDS(response, file = file_path)
  
fix_json <- function(model_provider_type="openai_gpt-4o-mini", df=json_class_responses) {
  
  
  ###
  # Parse model input string
  ###
  
  # Check validity of model_provider_type
  # Must be in format of provider_type, i.e. gemini_gemini-1.5-pro
  
  if (!is.character(model_provider_type) || length(model_provider_type) != 1) {
    stop("model_provider_type must be a single character string")
  }
  
  # Split into list of provider, type and check validity 
  
  parts <- str_split(model_provider_type, "_")[[1]]
  
  if (length(parts) != 2) stop("model_provider_type must be in format 'provider_model'")
  
  # Store component parts to pass to build 
  model_provider <- parts[1]
  model_type <- parts[2]
  
  ###
  # Create save directory
  ###
  
  save_dir <- file.path("../llm_responses", model_provider, model_type)
  dir.create(save_dir, recursive = TRUE, showWarnings = FALSE)
  
  ###
  # Create log file
  ### 
  log_file <- file.path(save_dir, "error_log.csv")
  #if (overwrite || !file.exists(log_file)) {
    write.csv(data.frame(
      timestamp = character(),
      article_id = character(),
      error = character(),
      stringsAsFactors = FALSE
    ), log_file, row.names = FALSE)
  #}
  
  ###
  # Set number of articles to pass through models
  ###
  
  result_df <- test_set_articles_df %>% 
    slice(1:sample_size)
  
  ###
  # Extract articles and article IDs into lists
  ###
  
  articles <- result_df %>% 
    pull(article)
  
  article_ids <- result_df %>% 
    pull(article_id)
  
  ###
  # Loop through articles and apply process_article function
  ###
  
  walk(seq_along(articles), 
       ~process_article(i = .x, 
                        article_ids = article_ids, 
                        articles = articles, 
                        save_dir = save_dir, 
                        model_provider = model_provider, 
                        model_type = model_type, 
                        overwrite=overwrite,
                        model_provider_type=model_provider_type,
                        log_file=log_file))
  print(paste0("finished processing ", model_provider_type))
}
    
  
    
  
  
  mutate(raw_response_clean = if_else(valid_json_in_raw_response,
                                      raw_response,
                                      str_trim(raw_response))) %>%
  mutate(valid_json_in_raw_response_2 = map_lgl(raw_response_clean, ~tryCatch(
    jsonlite::validate(.x),
    error = function(e) FALSE
  ))) %>%
  filter(valid_json_in_raw_response == FALSE) %>%
  filter(valid_json_in_raw_response_2 == TRUE)
  
  
  
  slice(1) %>%
  pull(raw_response)
  mutate(valid_json_in_raw_response_2 = map_lgl(raw_response_clean, ~tryCatch(
    jsonlite::validate(.x),
    error = function(e) FALSE
  ))) 





#  mutate(valid_json_in_raw_response = if_else(is.na(valid_json_in_raw_response), FALSE, valid_json_in_raw_response)) %>%  
 # ))
  #mutate(raw_response_clean = str_remove(raw_response, "^[^{]*")) %>%
  #mutate(raw_response_clean = str_remove(raw_response_clean, "\\}[^\\}]*$")) %>%
  mutate(raw_response_clean = str_remove(raw_response, "^```json\n*")) %>%
  mutate(raw_response_clean = str_remove(raw_response_clean, "\n*```$")) %>%
  

x <- responses %>%
  # mutate new column extracted json that detects whether response is valid json
  mutate(extracted_json = try(jsonlite::isJSON(raw_response)) ) %>%
  mutate(extracted_json = try(jsonlite::fromJSON(raw_response)) )
  tryCatch({
        parsed <- jsonlite::fromJSON(json)
        create_row(article_id, model_provider, model_type, json, parsed)
      }, error = function(e) {
      warning(sprintf("Failed to parse JSON for file %s: %s\nResponse: %s", file, as.character(e), json))
      create_empty_row(article_id, model_provider, model_type, raw_response)
      })
  }
  })}



%>%
  group_by(model_provider, model_type) %>%
  count()

##
# Create objects that evaluate model completeness
##
model_completeness_status <- get_model_completeness_status()

model_completeness_status_df <- model_completeness_status$provider_model_type_status_df  
provider_model_type_rerun_list <- model_completeness_status$provider_model_type_rerun_list
article_status_matrix <- model_completeness_status$article_status_matrix
###
# Rerun failed models
###

# We'll set at 4 for now
#workers <- 4
#source("r_scripts/03_04_r_classify_articles.R")

# Set up parallel processing
workers <- parallel::detectCores() - 1
future::plan(future::multisession, workers = workers)
z <- future::plan(future::multisession, workers = workers)
# Run classification in parallel
future_map(
  provider_model_type_rerun_list,
  classify_articles,
  system_prompt = system_prompt_value,
  test_set_articles_df = test_data,
  sample_size = nrow(test_data),
  overwrite = FALSE,
  .progress = TRUE
)
#nrow(test_set_articles)

classify_articles(
  model_provider_type = "gemini_gemini-1.5-pro",
  model_for_json_reparse = "gemini_gemini-1.5-flash",
  system_prompt = system_prompt_value,
  test_set_articles_df = test_data,
  sample_size = nrow(test_data),
  overwrite = FALSE
)
```


```{r}
# function to read in all rds files located inside folder llm_responses recursively and row bind use map_dfr

read_llm_responses <- function() {
  
  # initiate multisession
  workers <- parallel::detectCores() - 1
  future::plan(future::multisession, workers = workers)

  # Get all folders in llm_responses
  providers <- list.dirs("../llm_responses", recursive = FALSE, full.names = FALSE)
  
  results <- data.frame()
  #provider <- "groq"
  for (provider in providers) {
    # Get model folders for this provider
    model_folders <- list.dirs(file.path("../llm_responses", provider), 
                             recursive = FALSE, 
                             full.names = FALSE)
    #model <- model_folders[1]
    for (model in model_folders) {
      # Full path to check
      full_path <- file.path("../llm_responses", provider, model)
      
      # Get all .rds files (responses) and exclude error_log.csv
      files <- list.files(full_path, pattern = "*.rds", full.names = TRUE)
      
      # Read in all files
      
      responses <- furrr::future_map_dfr(files, read_csv, .progress=TRUE)
      
      # Add to results
      results <- rbind(results, responses)
    }
  }
  
  return(results)
}

llm_responses <- read_llm_responses()


```


```{r}
# function to read in all csv files located inside folder llm_responses recursively and row bind use map_dfr
read_error_logs <- function() {
  # Get all folders in llm_responses
  providers <- list.dirs("../llm_responses", recursive = FALSE, full.names = FALSE)
  
  results <- data.frame()
  #provider <- "groq"
  for (provider in providers) {
    # Get model folders for this provider
    model_folders <- list.dirs(file.path("../llm_responses", provider), 
                             recursive = FALSE, 
                             full.names = FALSE)
    #model <- model_folders[1]
    for (model in model_folders) {
      # Full path to check
      full_path <- file.path("../llm_responses", provider, model)
      
      # Get all .rds files (responses) and exclude error_log.csv
      files <- list.files(full_path, pattern = "error_log.csv", full.names = TRUE)
      
      # Read in all files
      responses <- purrr::map_dfr(files, read_csv)
      
      # Add to results
      results <- rbind(results, responses)
    }
  }
  
  return(results)
}

# error_logs <- read_error_logs()

```

```{r}
count_responses <- function() {
  # Get all folders in llm_responses
  providers <- list.dirs("llm_responses", recursive = FALSE, full.names = FALSE)
  
  results <- data.frame()
  
  for (provider in providers) {
    # Get model folders for this provider
    model_folders <- list.dirs(file.path("llm_responses", provider), 
                             recursive = FALSE, 
                             full.names = FALSE)
    
    for (model in model_folders) {
      # Full path to check
      full_path <- file.path("llm_responses", provider, model)
      
      # Count .rds files (responses) and exclude error_log.csv
      file_count <- length(list.files(full_path, pattern = "\\.rds$"))
      
      # Add to results
      results <- rbind(results, data.frame(
        provider = provider,
        model = model,
        responses = file_count
      ))
    }
  }
  
  return(results)
}

unfinished_file_counts <- count_responses() %>%
  filter(responses != max(responses))

unfinished_file_count_models <- unfinished_file_counts %>%
  mutate(model = paste0(provider, "_", model)) %>%
  #slice(3,4) %>%
  pull(model)

```

```{r}
###
# Define test function
###
library(furrr)
#sample_size <-1
#model_provider_type <- "openai_gpt-4o"
#workers <- 1
#i <- 1
classify_articles <- function(model_provider_type, sample_size=1, overwrite=FALSE) {
  if (!is.character(model_provider_type) || length(model_provider_type) != 1) {
    stop("model_provider_type must be a single character string")
  }
  
  parts <- str_split(model_provider_type, "_")[[1]]
  if (length(parts) != 2) stop("model_provider_type must be in format 'provider_model'")
  
  model_provider <- parts[1]
  model_type <- parts[2]
  
  save_dir <- file.path("llm_responses", model_provider, model_type)
  dir.create(save_dir, recursive = TRUE, showWarnings = FALSE)
  
  log_file <- file.path(save_dir, "error_log.csv")
  #if (overwrite || !file.exists(log_file)) {
    write.csv(data.frame(
      timestamp = character(),
      article_id = character(),
      error = character(),
      stringsAsFactors = FALSE
    ), log_file, row.names = FALSE)
  #}
  
  result_df <- test_set_articles %>% slice(1:sample_size)
  articles <- result_df %>% pull(article)
  article_ids <- result_df %>% pull(article_id)
  #i <- 1
  process_article <- function(i) {
    file_path <- file.path(save_dir, paste0(article_ids[i], ".rds"))
    if (!overwrite && file.exists(file_path)) {
      print(paste("Article", article_ids[i], "already processed"))
      return(NULL)
    }
    
    print(paste("Article", article_ids[i], "not yet processed, starting..."))

    chat <- if (model_provider == "ollama") {
      chat_ollama(model = model_type, system_prompt = system_prompt_value, echo = FALSE)
    } else if (model_provider == "groq") {
      chat_groq(model = model_type, system_prompt = system_prompt_value, echo = FALSE)
    } else if (model_provider_type %in% c("openai_o1-preview","openai_o1-mini")) {
      chat_openai(model = model_type, echo = FALSE)
    } else if (model_provider == "openai") {
      chat_openai(model = model_type, system_prompt = system_prompt_value, echo = FALSE)
    } else if (model_provider == "gemini") {
      chat_gemini(model = model_type, system_prompt = system_prompt_value, echo = FALSE)
    } else if (model_provider == "bedrock") {
      chat_bedrock(model = model_type, echo = FALSE)
    }
    
    text <- paste0("Article ID: ", article_ids[i], "\n\nArticle: ", articles[i])
    if (model_provider == "bedrock" | model_provider_type %in% c("openai_o1-preview","openai_o1-mini")) {
      text <- paste0("Instructions: ", system_prompt_value, "\nArticle ID: ", article_ids[i], "\nArticle to process: ", articles[i])
    }
    
    tryCatch({
      response <- chat$chat(text)
      saveRDS(response, file = file_path)
    }, error = function(e) {
      error_msg <- as.character(e)
      write.table(
        data.frame(
          timestamp = format(Sys.time(), "%Y-%m-%d %H:%M:%S"),
          article_id = article_ids[i],
          error = error_msg,
          stringsAsFactors = FALSE
        ),
        log_file,
        sep = ",",
        row.names = FALSE,
        col.names = !file.exists(log_file),
        append = TRUE
      )
      warning(sprintf("Row %d: Failed to get response for %s model %s.\nError: %s",
                     i, model_provider, model_type, error_msg))
    })
  }
  
  lapply(seq_along(articles), process_article)
  print(paste0("finished processing ", model_provider_type))
}

overwrite <- FALSE
model_provider_type <- "gemini_gemini-1.5-pro"
sample_size <- nrow(test_set_articles)
classify_articles(model_provider_type, sample_size, overwrite)

model_provider_type_list <- c(
  # Pass 1 
  "openai_gpt-4o",
  "groq_gemma2-9b-it",
  "bedrock_anthropic.claude-3-5-sonnet-20240620-v1:0",
  
  # Pass 2
  "openai_gpt-4o-mini", # works
  "groq_gemma-7b-it",# works
  "bedrock_anthropic.claude-v2:1", # works
  

  # Pass 3  
  "openai_gpt-4-turbo", # works
  "groq_llama3-groq-70b-8192-tool-use-preview",
  "bedrock_anthropic.claude-v2",# works
  

  # Pass 4
  "openai_gpt-4-turbo-preview", # works
  "groq_llama3-groq-8b-8192-tool-use-preview",
  "bedrock_anthropic.claude-instant-v1", # works
  
  # Pass 5
  "openai_gpt-3.5-turbo", # works
  "groq_llama-3.1-70b-versatile",# works
  "bedrock_anthropic.claude-3-haiku-20240307-v1:0", # works

  # Pass 6
  "openai_o1-preview",# works  
  "groq_llama-3.1-8b-instant",# works
  "bedrock_anthropic.claude-3-sonnet-20240229-v1:0", # works

  
  # Pass 7
  "openai_o1-mini",# works
  "groq_llama-3.2-1b-preview",# works

  # Pass 8
  "groq_llama-3.2-3b-preview",# works
  "bedrock_cohere.command-text-v14", # works
  


  # Pass 9 
  "groq_llama3-70b-8192",# works
  "bedrock_cohere.command-light-text-v14", # works
 

  # Pass 10 
  "groq_llama3-8b-8192",# works
  "bedrock_cohere.command-r-v1:0", # works
  

  # Pass 12  
  "groq_mixtral-8x7b-32768",# works
  "bedrock_cohere.command-r-plus-v1:0", # works
  #"gemini_gemini-exp-1114",#works

  # Pass 13
  "bedrock_ai21.jamba-1-5-large-v1:0", # this works
  #"gemini_gemini-exp-1121", #works

  # Pass 14
  "bedrock_ai21.jamba-1-5-mini-v1:0", # this works
  #"gemini_gemini-1.5-pro",
  
  # Pass 15
  "bedrock_meta.llama3-70b-instruct-v1:0", # this works
  #"gemini_gemini-1.5-flash",#works
  
  # Pass 16
  "bedrock_amazon.titan-text-premier-v1:0"#,# this works
  #"gemini_learnlm-1.5-pro-experimental"#works

)

# set workers to 1 less than number of cores
# model_provider_type_list <- c("bedrock_amazon.titan-text-premier-v1:0")

workers <- parallel::detectCores() - 1
future::plan(future::multisession, workers = workers)

model_provider_type_list <- unfinished_file_count_models
# Run classification in parallel
future_map(
  model_provider_type_list,
  classify_articles,
  sample_size = nrow(test_set_articles),
  overwrite = FALSE,
  .progress = TRUE
)
nrow(test_set_articles)
# Reset to sequential processing
#plan(sequential)

```

```{r}

combine_responses <- function(base_dir = "llm_responses") {
  files <- list.files(base_dir, pattern = "\\.rds$", recursive = TRUE, full.names = TRUE)
  
  responses <- map_dfr(files, function(file) {
    parts <- str_split(file, "/")[[1]]
    model_provider <- parts[2]
    model_type <- parts[3]
    article_id <- str_remove(basename(file), "\\.rds$")
    
    raw_response <- readRDS(file)
    response_parts <- str_split(raw_response, "Warning:")[[1]]
    response <- response_parts[1]
    
    json <- str_extract(response, "\\{[^}]*\\}")
    if (is.na(json)) {
      json <- str_extract(response, "\\{.*") %>%
      str_replace_all("\\\\_", "_") %>%
      str_replace_all("\\\\([nrt])", "") %>%
      str_replace_all("\\\\([^\"'\\\\])", "\\1") %>%
      str_replace_all("\\s+", " ") %>%
      str_trim()
      
      json <- paste0(json, "}")
      
    } else {
    #if (is.na(json)) return(create_empty_row(article_id, model_provider, model_type, raw_response))
    
    json <- json %>%
      str_replace_all("\\\\_", "_") %>%
      str_replace_all("\\\\([nrt])", "") %>%
      str_replace_all("\\\\([^\"'\\\\])", "\\1") %>%
      str_replace_all("\\s+", " ") %>%
      str_trim()
      
    }
    
    tryCatch({
      parsed <- jsonlite::fromJSON(json)
      create_row(article_id, model_provider, model_type, json, parsed)
    }, error = function(e) {
      warning(sprintf("Failed to parse JSON for file %s: %s\nResponse: %s", file, as.character(e), json))
      create_empty_row(article_id, model_provider, model_type, json)
    })
  })
  responses
}

# Helper functions
create_empty_row <- function(article_id, model_provider, model_type, raw_response) {
  tibble(
    article_id = article_id,
    model_provider = model_provider,
    model_type = model_type,
    raw_response = raw_response,
    spellchecked_text = NA_character_,
    category_id = NA_character_,
    category_description = NA_character_,
    explanation = NA_character_
  )
}

create_row <- function(article_id, model_provider, model_type, raw_response, parsed) {
  tibble(
    article_id = article_id,
    model_provider = model_provider,
    model_type = model_type,
    raw_response = raw_response,
    spellchecked_text = parsed$spellchecked_text %||% NA_character_,
    category_id = as.character(parsed$category_id) %||% NA_character_,
    category_description = parsed$category_description %||% NA_character_,
    explanation = as.character(parsed$explanation) %||% NA_character_
  )
}
responses <- combine_responses()

z <- responses %>% filter(is.na(spellchecked_text)) %>% pull(raw_response)

z

#readRDS("llm_responses/groq/gemma2-9b-it/3_1889-06-05_p13_sn96027724_00271761466_1889060501_0389.rds")

```

```{r}
quantification <- responses %>%
  mutate(category_id_clean = str_sub(category_id, 1, 1)) %>%
  #filter(category_id_clean %in% c("1","2","3","4","5","6")) %>%
  rename(predicted_class_id = category_id_clean) %>%
  inner_join(test_set_articles, by = "article_id") %>%
  mutate(actual_class_id = class_id) %>%
  select(1:3, predicted_class_id, actual_class_id,class_definition, everything()) %>%
  mutate(accurate_prediction = if_else(predicted_class_id == actual_class_id, "TRUE", "FALSE")) %>%
  mutate(temp=1) %>%
  group_by(model_provider,model_type, accurate_prediction) %>%
  summarise(total=sum(temp)) %>%
  ungroup() %>%
  pivot_wider(names_from=accurate_prediction, values_from=total) %>%
  mutate(total_predictions = `TRUE` + `FALSE`) %>%
  # percent total accurate predictions
  mutate(percent_accurate = (`TRUE`/total_predictions)*100)

```

```{r}


# Human-classified story set
# If tuning a model, can be split into test and training
# For our purposes, since we're not tuning a model, we'll use the whole set
# test_set <- read_sheet("https://docs.google.com/spreadsheets/d/1zleETBjVMOwLMYTouK7UHWzQx53H2q2oN_S3mj5tqlk/edit?gid=2053814490#gid=2053814490", sheet="test_slash_training_set") %>%
#   janitor::clean_names() %>%
#   # extract four digit number between first _ and first -  in article_id into a new column called year
#   mutate(year = str_extract(article_id, "(?<=_)(\\d{4})(?=-)")) %>%
#   # extract first number from class and put in a new col called class_id
#   mutate(class_id = str_extract(class, "\\d+")) %>%
#   # extract everything but first number from class and put in a new col called class_definition
#   mutate(class_definition = str_remove(class, "\\d+")) %>%
#   # trim whitespace from class_definition and to lower
#   mutate(class_definition = tolower(str_squish(class_definition))) %>%
#   select(article_id, year, class_id, class_definition)


# use map_dfr to read in feather file for each year stored at build_american_stories_dataset/data_by_year/arrow/articles_YEAR.feather and bind them together
# create a list of distinct years
# years <- test_set %>% distinct(year) %>% pull(year)

years <- c("1891", "1915", "1913", "1890", "1902")

# Pattern 1: Lynching of colored people
pattern1 <- "lynching[s]?\\W+of\\W+(the\\W+)?(\\w+\\W+){1,2}?colored"
pattern2 <- "(murderer|fiend|desperado|brute)\\W+(\\w+\\W+){1,2}?lynch(ed|es|ing)?(\\W+|$)"
pattern3 <- "colored[s]?\\W+(\\w+\\W+){1,2}?((was|were)\\W+)?lynch(ed|es|ing)?(\\W+|$)"
pattern4 <- "lynching[s]?\\W+of\\W+(the\\W+)?(\\w+\\W+){1,2}?negro"
pattern5 <- "mob\\W+(\\w+\\W+){1,2}?(hung|hang(ed|ings?|s)|lynch(ed|es|ing)?)"
pattern6 <- "negro(e?s)?\\W+(\\w+\\W+){1,2}?((was|were)\\W+)?lynch(ed|es|ing)?(\\W+|$)"
regex_pattern <- paste0(pattern1,"|",pattern2,"|",pattern3,"|",pattern4,"|",pattern5,"|",pattern6)


read_and_filter <- function(year) {
  
  temp <- arrow::read_feather(paste0("build_american_stories_dataset/data_by_year/arrow/articles_", year, ".feather")) %>%
  # make article lowercase, remove all punctuation and numbers
  mutate(article_clean = str_to_lower(article)) %>%
  # remove punct
  mutate(article_clean = str_replace_all(article_clean, "[[:punct:]]", " ")) %>%
  # remove numbers
  mutate(article_clean = str_replace_all(article_clean, "[[:digit:]]", " ")) %>%
  # remove internal whitespace
  mutate(article_clean = str_squish(article_clean)) %>%
  mutate(jack_regex_match = str_detect(article_clean, regex_pattern)) %>%
  filter(jack_regex_match == TRUE) 

  return(temp)  
  
}

plan(multisession, workers = 5)

test_set_articles <- future_map_dfr(years, read_and_filter)

x <- test_set_articles %>%
  mutate(check = if_else(str_detect(article_clean,"orderly|judge lynch|citizen"), "TRUE", "FALSE")) 

sheet_write(x, "https://docs.google.com/spreadsheets/d/1zleETBjVMOwLMYTouK7UHWzQx53H2q2oN_S3mj5tqlk/edit?gid=2053814490#gid=2053814490", sheet="orderly_justice_judge_citizens")




not_lynch <- df_clean %>%
  filter(!str_detect(article_clean,"lynch")) %>%
  filter(jack_regex_match != TRUE)

judge <- df_clean %>%
  filter(str_detect(article_clean,"judge lynch")) 



```
