---
title: "final_final_project"
---

```{r}
###
# Load libraries
###

# Data science goodness
library(tidyverse)
library(googlesheets4)
library(janitor)

# Elmer for LLM calling https://elmer.tidyverse.org/index.html To install ## #pak::pak("tidyverse/elmer")
library(elmer)

# For the paralell speed we love so much
library(future)
library(furrr)

# For loading feather files
library(arrow)

library(paws.common)
#library(paws)

###
# API Keys
###
# To work with elmer, keys need to be stored in the .Renviron file
# Run to open renviron file to edit usethis::edit_r_environ() 
# may need to restart R after
# Note that the .renviron file seems to be stored at like r root, maybe, not in project directory?
# Check it is set Sys.getenv("OPENAI_API_KEY")

# For this script, need the following keys
# ATTENTION: do not uncomment these keys here, they need to be stored in the .Renviron file. This is just for your information, man. 
# Open AI
#OPENAI_API_KEY = "key_here"

# Groq
# GROQ_API_KEY = "key_here"

# Amazon Bedrock
#AWS_ACCESS_KEY_ID = ""
#AWS_SECRET_ACCESS_KEY = "key_here"
#AWS_REGION = "key_here"

# Google Gemini (not sure if have to call it google or gemini, so using both )
#GEMINI_API_KEY = "key_here"
#GOOGLE_API_KEY = "key_here"

# If all of these keys are set, then you can run the following to check
print(paste0("OPENAI_API_KEY: ",Sys.getenv("OPENAI_API_KEY")))
print(paste0("GROQ_API_KEY: ",Sys.getenv("GROQ_API_KEY")))
print(paste0("AWS_ACCESS_KEY_ID: ",Sys.getenv("AWS_ACCESS_KEY_ID")))
print(paste0("AWS_SECRET_ACCESS_KEY: ",Sys.getenv("AWS_SECRET_ACCESS_KEY")))
print(paste0("AWS_REGION: ",Sys.getenv("AWS_REGION")))
print(paste0("GEMINI_API_KEY: ",Sys.getenv("GEMINI_API_KEY")))
print(paste0("GOOGLE_API_KEY: ",Sys.getenv("GOOGLE_API_KEY")))

```

```{r}
###
# Load test set
###

# Human-classified story set
# If tuning a model, can be split into test and training
# For our purposes, since we're not tuning a model, we'll use the whole set
test_set <- read_sheet("https://docs.google.com/spreadsheets/d/1zleETBjVMOwLMYTouK7UHWzQx53H2q2oN_S3mj5tqlk/edit?gid=2053814490#gid=2053814490", sheet="test_slash_training_set") %>%
  janitor::clean_names() %>%
  # extract four digit number between first _ and first -  in article_id into a new column called year
  mutate(year = str_extract(article_id, "(?<=_)(\\d{4})(?=-)")) %>%
  # extract first number from class and put in a new col called class_id
  mutate(class_id = str_extract(class, "\\d+")) %>%
  # extract everything but first number from class and put in a new col called class_definition
  mutate(class_definition = str_remove(class, "\\d+")) %>%
  # trim whitespace from class_definition and to lower
  mutate(class_definition = tolower(str_squish(class_definition))) %>%
  select(article_id, year, class_id, class_definition)


# use map_dfr to read in feather file for each year stored at build_american_stories_dataset/data_by_year/arrow/articles_YEAR.feather and bind them together
# create a list of distinct years
# years <- test_set %>% distinct(year) %>% pull(year)
# initiate paralell rig
# plan(multisession)
# test_set_articles <- future_map_dfr(years, ~arrow::read_feather(paste0("build_american_stories_dataset/data_by_year/arrow/articles_", .x, ".feather"))) %>%
#  inner_join(test_set, by=c("article_id"="article_id"))


# Write out test_set_articles to a feather file
# arrow::write_feather(test_set_articles, "test_set_articles.feather")
# Read in to save time later
test_set_articles <- arrow::read_feather("test_set_articles.feather")

test_set_articles <- test_set_articles #%>%
 # slice(1:5)

```

```{r}
###
# Build system prompt
###

system_prompt_value <- "You are an expert in classifying historical newspaper articles about lynchings in the United States between 1865 and 1922. You always follow instructions.
I will give you the text of a newspaper article and an associated article_id. The text can classified into one of six distinct categories:
1. An article that describes a specific lynching event that has already happened.
2. An article that does not describe a specific lynching event that has already happened, but does suggest a lynching event may happen in the future. 
3. An article that does not describe a specific lynching event that has already happened, does not suggest a lynching event may happen in the future, but is about federal, state or local policies or laws governing lynching or describes debate over proposed laws.
4. An article that contains strings or partial strings typically found in stories associated with lynching -- like the word 'lynching' or 'lynch' -- but does not describe past or possible lynching events or lynching laws and policies. This could include an article that mentions someone whose last name is Lynch, or a reference toa city that includes 'lynch' as part of its name, like Lynchburg, Va.
5. An article that contains no strings or partial strings typically found in stories associated with lynching and not describe past or possible lynching events or lynching laws and policies.
6. An article that does not fit into any of the first five categories.
Please do the following:
-- The article text provided here was extracted from newspaperpage images through an imperfect OCR process. Do your best to correct any flaws introduced in this process, without changing meaning of the article. You should spellcheck the text and correct spelling errors, standardize capitalization, fix extraneous spaces, remove newline characters and random slashes, separate words that have obviously been concatenated in error, remove non alphabetic or standard punctuation characters. Of special importance is to correct any errors that will prevent the json from being parsed correctly later. 
-- Select the category that best describes the article text. Choose only one. 
-- Develop a brief explanation of why you chose a specific category, including keywords or terms that support the decision.

Format your response as a JSON object with these exact fields:
{
    \"article_id\": \"string, unchanged from input\",
    \"spellchecked_text\": \"string, corrected spelling of article\",
    \"category_id\": \"string, single digit 1-6\",
    \"category_description\": \"string, exact category description from above\",
    \"explanation\": \"string, brief reason for classification\"
}

Important formatting rules:
- Use double quotes for all strings
- No line breaks in text fields
- No trailing commas
- No comments or additional text
- No markdown formatting
- Escape all quotes within text using single quotes
- Remove any \\r or \\n characters from text
- End the JSON object with a single closing curly brace }"




# system_prompt_value <- "You are an expert in classifying historical newspaper articles about lynchings in the United States between 1865 and 1922. You always follow instructions.
# 
# I will give you the text of a newspaper article and an associated article_id. The text can classified into one of six distinct categories:
# 
# 1. An article that describes a specific lynching event that has already happened.
# 2. An article that does not describe a specific lynching event that has already happened, but does suggest a lynching event may happen in the future. 
# 3. An article that does not describe a specific lynching event that has already happened, does not suggest a lynching event may happen in the future, but is about federal, state or local policies or laws governing lynching or describes debate over proposed laws.
# 4. An article that contains strings or partial strings typically found in stories associated with lynching -- like the word 'lynching' or 'lynch' -- but does not describe past or possible lynching events or lynching laws and policies. This could include an article that mentions someone whose last name is Lynch, or a reference to Lynchburg, Va.
# 5. An article that contains no strings or partial strings typically found in stories associated with lynching and not describe past or possible lynching events or lynching laws and policies.
# 6. An article that does not fit into any of the first five categories.
# 
# Please do the following:
# 
# -- Because of flaws in the OCR process, the article text extracted from page images is often flawed. Do your best to correct these flaws, without changing meaning of the article. You should spellcheck the text and correct spelling errors, standardize capitalization, fix extraneous spaces, remove newline characters and random slashes, separate words that have obviously been concatenated in error, remove non alphabetic or standard punctuation characters. Of special importance is to correct any errors that will prevent the json from being parsed correctly. 
# -- Select the category that best describes the article text. Choose only one. 
# -- Develop a brief explanation of why you chose a specific category, including keywords or terms that support the decision.
# 
# Return a valid json object -- and only a valid json object, NOTHING more -- with four key-value pairs: 'article_id', 'spellchecked_text', 'category_id', 'category_description', 'explanation'. Populate the values as follows:
# 
# --'article_id': The provided article_id, without modification
# --'spellchecked_text': The corrected spelling of the article text
# --'category_id': The number of the category you chose, which is the first digit of each category provided above
# --'category_description': The full description of the category you chose, without modification
# --'explanation': A brief explanation of why you chose the category you did, including keywords or terms that support the decision.
# 
# For example, if you chose category 1, the json object might look like this:
# 
# This is an example of a properly formatted json object. Do not deviate from this format:
# {'article_id': '10_1889-07-25_p1_sn84023017_00414212992_1889072507_0484', 'spellchecked_text': 'A negro man named Tom Smith was lynched in Albany, Georgia yesterday by a town mob.', 'category_id': '1', 'category_description': 'An article that describes a specific lynching event that has already happened.', 'explanation': 'The text uses the past tense was lynched to describe a specific person who was lynched by a mob'}   
# 
# Return only json in this format.  Do not include tick marks or the word json to indicate you are returning json.  Do not include newline characters in your response. A properly formatted response opens with a { and ends with a }"

```

```{r}
###
# Define test function
###
library(furrr)
#sample_size <-1
#model_provider_type <- "openai_gpt-4o"
#workers <- 1
#i <- 1
classify_articles <- function(model_provider_type, sample_size=1, overwrite=FALSE) {
  if (!is.character(model_provider_type) || length(model_provider_type) != 1) {
    stop("model_provider_type must be a single character string")
  }
  
  parts <- str_split(model_provider_type, "_")[[1]]
  if (length(parts) != 2) stop("model_provider_type must be in format 'provider_model'")
  
  model_provider <- parts[1]
  model_type <- parts[2]
  
  save_dir <- file.path("llm_responses", model_provider, model_type)
  dir.create(save_dir, recursive = TRUE, showWarnings = FALSE)
  
  log_file <- file.path(save_dir, "error_log.csv")
  if (overwrite || !file.exists(log_file)) {
    write.csv(data.frame(
      timestamp = character(),
      article_id = character(),
      error = character(),
      stringsAsFactors = FALSE
    ), log_file, row.names = FALSE)
  }
  
  result_df <- test_set_articles %>% slice(1:sample_size)
  articles <- result_df %>% pull(article)
  article_ids <- result_df %>% pull(article_id)
  
  process_article <- function(i) {
    file_path <- file.path(save_dir, paste0(article_ids[i], ".rds"))
    if (!overwrite && file.exists(file_path)) return(NULL)
    
    chat <- if (model_provider == "ollama") {
      chat_ollama(model = model_type, system_prompt = system_prompt_value, echo = FALSE)
    } else if (model_provider == "groq") {
      chat_groq(model = model_type, system_prompt = system_prompt_value, echo = FALSE)
    } else if (model_provider_type %in% c("openai_o1-preview","openai_o1-mini")) {
      chat_openai(model = model_type, echo = FALSE)
    } else if (model_provider == "openai") {
      chat_openai(model = model_type, system_prompt = system_prompt_value, echo = FALSE)
    } else if (model_provider == "gemini") {
      chat_gemini(model = model_type, system_prompt = system_prompt_value, echo = FALSE)
    } else if (model_provider == "bedrock") {
      chat_bedrock(model = model_type, echo = FALSE)
    }
    
    text <- paste0("Article ID: ", article_ids[i], "\n\nArticle: ", articles[i])
    if (model_provider == "bedrock" | model_provider_type %in% c("openai_o1-preview","openai_o1-mini")) {
      text <- paste0("Instructions: ", system_prompt_value, "\nArticle ID: ", article_ids[i], "\nArticle to process: ", articles[i])
    }
    
    tryCatch({
      response <- chat$chat(text)
      saveRDS(response, file = file_path)
    }, error = function(e) {
      error_msg <- as.character(e)
      write.table(
        data.frame(
          timestamp = format(Sys.time(), "%Y-%m-%d %H:%M:%S"),
          article_id = article_ids[i],
          error = error_msg,
          stringsAsFactors = FALSE
        ),
        log_file,
        sep = ",",
        row.names = FALSE,
        col.names = !file.exists(log_file),
        append = TRUE
      )
      warning(sprintf("Row %d: Failed to get response for %s model %s.\nError: %s",
                     i, model_provider, model_type, error_msg))
    })
  }
  
  lapply(seq_along(articles), process_article)
  print(paste0("finished processing ", model_provider_type))
}

model_provider_type_list <- c(
  # Pass 1 
  "openai_gpt-4o",
  "groq_gemma2-9b-it",
  "bedrock_anthropic.claude-3-5-sonnet-20240620-v1:0",
  
  # Pass 2
  "openai_gpt-4o-mini", # works
  "groq_gemma-7b-it",# works
  "bedrock_anthropic.claude-v2:1", # works
  

  # Pass 3  
  "openai_gpt-4-turbo", # works
  "groq_llama3-groq-70b-8192-tool-use-preview",
  "bedrock_anthropic.claude-v2",# works
  

  # Pass 4
  "openai_gpt-4-turbo-preview", # works
  "groq_llama3-groq-8b-8192-tool-use-preview",
  "bedrock_anthropic.claude-instant-v1", # works
  
  # Pass 5
  "openai_gpt-3.5-turbo", # works
  "groq_llama-3.1-70b-versatile",# works
  "bedrock_anthropic.claude-3-haiku-20240307-v1:0", # works

  # Pass 6
  "openai_o1-preview",# works  
  "groq_llama-3.1-8b-instant",# works
  "bedrock_anthropic.claude-3-sonnet-20240229-v1:0", # works

  
  # Pass 7
  "openai_o1-mini",# works
  "groq_llama-3.2-1b-preview",# works

  # Pass 8
  "groq_llama-3.2-3b-preview",# works
  "bedrock_cohere.command-text-v14", # works
  


  # Pass 9 
  "groq_llama3-70b-8192",# works
  "bedrock_cohere.command-light-text-v14", # works
 

  # Pass 10 
  "groq_llama3-8b-8192",# works
  "bedrock_cohere.command-r-v1:0", # works
  

  # Pass 12  
  "groq_mixtral-8x7b-32768",# works
  "bedrock_cohere.command-r-plus-v1:0", # works
  #"gemini_gemini-exp-1114",#works

  # Pass 13
  "bedrock_ai21.jamba-1-5-large-v1:0", # this works
  #"gemini_gemini-exp-1121", #works

  # Pass 14
  "bedrock_ai21.jamba-1-5-mini-v1:0", # this works
  #"gemini_gemini-1.5-pro",
  
  # Pass 15
  "bedrock_meta.llama3-70b-instruct-v1:0", # this works
  #"gemini_gemini-1.5-flash",#works
  
  # Pass 16
  "bedrock_amazon.titan-text-premier-v1:0"#,# this works
  #"gemini_learnlm-1.5-pro-experimental"#works

)

# set workers to 1 less than number of cores
# model_provider_type_list <- c("bedrock_amazon.titan-text-premier-v1:0")

workers <- parallel::detectCores() - 1
future::plan(future::multisession, workers = workers)

model_provider_type_list
# Run classification in parallel
future_map(
  model_provider_type_list,
  classify_articles,
  sample_size = nrow(test_set_articles),
  overwrite = FALSE,
  .progress = TRUE
)
nrow(test_set_articles)
# Reset to sequential processing
#plan(sequential)

```

```{r}

combine_responses <- function(base_dir = "llm_responses") {
  files <- list.files(base_dir, pattern = "\\.rds$", recursive = TRUE, full.names = TRUE)
  
  responses <- map_dfr(files, function(file) {
    parts <- str_split(file, "/")[[1]]
    model_provider <- parts[2]
    model_type <- parts[3]
    article_id <- str_remove(basename(file), "\\.rds$")
    
    raw_response <- readRDS(file)
    response_parts <- str_split(raw_response, "Warning:")[[1]]
    response <- response_parts[1]
    
    json <- str_extract(response, "\\{[^}]*\\}")
    if (is.na(json)) {
      json <- str_extract(response, "\\{.*") %>%
      str_replace_all("\\\\_", "_") %>%
      str_replace_all("\\\\([nrt])", "") %>%
      str_replace_all("\\\\([^\"'\\\\])", "\\1") %>%
      str_replace_all("\\s+", " ") %>%
      str_trim()
      
      json <- paste0(json, "}")
      
    } else {
    #if (is.na(json)) return(create_empty_row(article_id, model_provider, model_type, raw_response))
    
    json <- json %>%
      str_replace_all("\\\\_", "_") %>%
      str_replace_all("\\\\([nrt])", "") %>%
      str_replace_all("\\\\([^\"'\\\\])", "\\1") %>%
      str_replace_all("\\s+", " ") %>%
      str_trim()
      
    }
    
    tryCatch({
      parsed <- jsonlite::fromJSON(json)
      create_row(article_id, model_provider, model_type, json, parsed)
    }, error = function(e) {
      warning(sprintf("Failed to parse JSON for file %s: %s\nResponse: %s", file, as.character(e), json))
      create_empty_row(article_id, model_provider, model_type, json)
    })
  })
  responses
}

# Helper functions
create_empty_row <- function(article_id, model_provider, model_type, raw_response) {
  tibble(
    article_id = article_id,
    model_provider = model_provider,
    model_type = model_type,
    raw_response = raw_response,
    spellchecked_text = NA_character_,
    category_id = NA_character_,
    category_description = NA_character_,
    explanation = NA_character_
  )
}

create_row <- function(article_id, model_provider, model_type, raw_response, parsed) {
  tibble(
    article_id = article_id,
    model_provider = model_provider,
    model_type = model_type,
    raw_response = raw_response,
    spellchecked_text = parsed$spellchecked_text %||% NA_character_,
    category_id = parsed$category_id %||% NA_character_,
    category_description = parsed$category_description %||% NA_character_,
    explanation = parsed$explanation %||% NA_character_
  )
}
responses <- combine_responses()

z <- responses %>% filter(is.na(spellchecked_text)) %>% pull(raw_response)

z

#readRDS("llm_responses/groq/gemma2-9b-it/3_1889-06-05_p13_sn96027724_00271761466_1889060501_0389.rds")

```

```{r}
x <- responses %>%
mutate(category_id_clean = str_sub(category_id, 1, 1)) %>%
filter(category_id_clean %in% c("1","2","3","4","5","6")) %>%
rename(predicted_class_id = category_id_clean) %>%
inner_join(test_set_articles, by = "article_id") %>%
mutate(actual_class_id = class_id) %>%
select(1:3, predicted_class_id, actual_class_id,class_definition, everything()) %>%
mutate(accurate_prediction = if_else(predicted_class_id == actual_class_id, "TRUE", "FALSE")) %>%
mutate(temp=1) %>%
group_by(model_provider,model_type, accurate_prediction) %>%
summarise(total=sum(temp)) %>%
ungroup() %>%
pivot_wider(names_from=accurate_prediction, values_from=total) %>%
mutate(total_predictions = `TRUE` + `FALSE`) %>%
# percent total accurate predictions
mutate(percent_accurate = (`TRUE`/total_predictions)*100)

```